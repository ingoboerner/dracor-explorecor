{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796a4fdb-00df-42a7-b139-a70bae1a78c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(chapter-1-3)=\n",
    "# 1.3 Using DraCor: Four Showcases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd986208-22d0-45cc-9d38-5c2d69cd72df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this section we will give an idea of possible uses of DraCor as a prototype of a *Programmable Corpus Enviroinment* by showcasing four examples which are included in this Jupyter Notebook[^source_of_notebook]:\n",
    "\n",
    "[^source_of_notebook]: This Jupyter Notebook is based on CLS INFRA Deliverable [D7.1 Report \"On Programmable Corpora\"](https://zenodo.org/records/7664964) {cite:p}`boerner_2023_report`. The showcases are re-implemented in Python whenever possible and have been adapted to the latest major DraCor API Version 1.0. We present this in a form similar to our [\"Executeable Report\"](https://versioning-living-corpora.clsinfra.io) which accompanies CLS INFRA Deliverable [D7.3 \"On Versioning Living and Programmable Corpora\"](https://zenodo.org/records/11081934) {cite:p}`boerner_2024_versioning-living-corpora`.\n",
    "\n",
    "* first, a basic one-click download of modeled text data;\n",
    "* second, an approach to geo-based visualization of corpus metadata using Linked Open Data;\n",
    "* third, an API-based approach to standardized extraction of specific textual data across different corpora; and\n",
    "* fourth, a method-based approach based on Social Network Analysis metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567589c9-c906-4b68-bfcd-d74ab09a7a06",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is needed to provide a functionality for the HTML rendering of the Jupyter Book; \n",
    "# please ignore if viewing this Notebook in Jupyter Lab\n",
    "from myst_nb import glue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc574d35-d6c5-40cb-943f-322cbb2ef4cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-1-3-1)=\n",
    "## 1.3.1 Showcase 1: One-Click Download of Modeled Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e1eb4-f1a8-478e-b801-cb40a2772ec0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "When considering an ecosystem for Computational Literary Studies, one usually thinks of\n",
    "applications that operate at a relatively sophisticated technical resp. computational level. But\n",
    "actually, it is central to the development of the discipline and its infrastructures that it remains\n",
    "accessible even to novices and beginners. It is also for this reason that an essential component\n",
    "of DraCor is a user-friendly front-end that, on the one hand, provides a set of\n",
    "services with an easily accessible graphical user interface (GUI) and, on the other hand, allows\n",
    "access to the corpora data with as little technical expertise as possible. The frontend with its\n",
    "graphical user interface thus also assumes didactic functions: Texts can be easily navigated\n",
    "through various tabs and viewed in different shapes and modes of modeling.\n",
    "\n",
    "For example, any play from the corpora contained in DraCor can be displayed in a text\n",
    "view that does not differ significantly from classic ways of displaying texts in e-readers or web\n",
    "browsers (see {numref}`fulltext-view`). While texts appear in such a full-text view as conventional epistemic\n",
    "objects of literary studies (ready for close reading), after a tab change (see {numref}`download-tab`), one-click\n",
    "downloads of differently modeled derivations from these full texts can be downloaded for “distant\n",
    "reading” (Moretti 2013)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf108f47-00b1-42da-937f-81f2da6923e7",
   "metadata": {},
   "source": [
    "% Figure is rendered in the HTML output here\n",
    "\n",
    "```{figure} ./images/fulltext-view.png\n",
    "---\n",
    "width: 600px\n",
    "name: fulltext-view\n",
    "---\n",
    "Full text view of a DraCor play in the front-end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe26314-cebd-40be-8d2a-1ad242296abd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "% Figure is rendered in the HTML output here\n",
    "\n",
    "```{figure} ./images/download-tab.png\n",
    "---\n",
    "width: 600px\n",
    "name: download-tab\n",
    "---\n",
    "Download options for a DraCor play in the front-end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc47ec7-a76d-408c-8ef9-a2397ab78f3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This allows DraCor to introduce the different epistemic and technical manifestations of text in the CLS in an easily accessible way. Furthermore, it is also possible to work with these modeled text data immediately, which allows a quick introduction to methods and tools of the CLS.\n",
    "\n",
    "For this showcase, we choose to use the data of a co-occurrence network (i.e. a network of characters connected via their co-presence on the stage), downloading the XML-based GEXF format that can be opened with open source programming libraries such as [networkx](https://networkx.org) {cite:p}`hagberg_2008_networkx` or the widely used open source desktop software [Gephi](https://gephi.org) {cite:p}`bastian_2009_gephi`. With a few clicks after the download, it is thus possible to create a network graph (see Fig. 03) that now allows the literary text to be viewed in an entirely different modeling mode, predestined for distant reading {cite:p}`moretti_2011_network`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e93ebd-83f0-4cbe-983c-e5055975726f",
   "metadata": {},
   "source": [
    "% Figure is rendered in the HTML output here\n",
    "\n",
    "```{figure} ./images/gephi-oneclick-networkgraph.png\n",
    "---\n",
    "width: 600px\n",
    "name: gephi-oneclick-networkgraph\n",
    "---\n",
    "Network visualization with Gephi, based on a DraCor one-click download\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9a2c0-e991-43a5-b317-044b5dc19224",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In Session 5 on Wednesday we will demonstrate how do do network analysis with DraCor in Gephi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0569a06-908e-48a6-8d5b-be4fd2affa66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-1-3-2)=\n",
    "## 1.3.2 Showcase 2: Geo-Mapping Locations of First Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad0890-da09-4830-ba14-212c53585b04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "However, DraCor's beginner-friendly front-end is just one way to access and use the data in this\n",
    "Programmable Corpus. Instead, the computational literary scholar will usually access the data\n",
    "either directly in the form of the TEI-XML[^tei] or via the various APIs and API endpoints. In the\n",
    "following showcase, the focus is on DraCor’s SPARQL[^sparql] endpoint.\n",
    "\n",
    "[^tei]: TEI-XML is a type of the XML format that complies the standards defined by the “Text Encoding Initiative (TEI)”, cf. [https://tei-c.org](https://tei-c.org)\n",
    "\n",
    "[^sparql]: [SPARQL Specification](https://www.w3.org/TR/sparql11-query). A tutorial on how to use SPARQL to query Wikidata can be accessed at [https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial](https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial)\n",
    "\n",
    "During the homogenization of metadata that theater plays undergo as part of the\n",
    "integration into the DraCor environment, [Wikidata identifiers](https://www.wikidata.org/wiki/Wikidata:Identifiers) (entity IDs) for both authors and\n",
    "individual works are typically included in the metadata of each play encoded in the <teiHeader>.\n",
    "For example, for the German-language bourgeois tragedy “Emilia Galloti” by Gotthold Ephraim\n",
    "Lessing this data is available in DraCor (`<idno @type=\"wikidata\">`). First for the author:[^author_wikidata_encoding_example]\n",
    "\n",
    "\n",
    "[^author_wikidata_encoding_example]: [Source of the cited code snippet](https://github.com/dracor-org/gerdracor/blob/3dc874101e2d10d687510aeb5ff8a907331843c1/tei/lessing-emilia-galotti.xml#L10-L18)\n",
    "\n",
    "\n",
    "```\n",
    "<author>\n",
    "    <persName>\n",
    "        <forename>Gotthold</forename>.\n",
    "        <forename>Ephraim</forename>\n",
    "        <surname>Lessing</surname>\n",
    "    </persName>\n",
    "    <idno type=\"wikidata\">Q34628</idno>\n",
    "    <idno type=\"pnd\">118572121</idno>\n",
    "</author>\n",
    "```\n",
    "\n",
    "Then for the individual work:[^link_to_wikidata_example]\n",
    "\n",
    "```\n",
    "<listRelation>\n",
    "    <relation name=\"wikidata\" active=\"https://dracor.org/entity/ger000088\"\n",
    "        passive=\"http://www.wikidata.org/entity/Q782653\"/>\n",
    "</listRelation>\n",
    "```\n",
    "\n",
    "[^link_to_wikidata_example]: [Source of the cited code snippet](https://github.com/dracororg/gerdracor/blob/3dc874101e2d10d687510aeb5ff8a907331843c1/tei/lessing-emilia-galotti.xml#L122-L124)\n",
    "\n",
    "Thanks to this metadata, the plays in DraCor can be linked to further information from, among others, [Wikidata](https://www.wikidata.org)[^dracor_wikidata_property], thus be embedded in the wide ecosystem of Linked Open Data and thereby benefit from the often crowd-based data enrichment projects in the World Wide Web. For example, numerous Wikidata entries on plays contain information about the “location of first performances”.[^location_of_first_performance_property] In the case of Lessing's \"Emilia Galotti\", this location is the \"Hagenmarkt-Theater\", which also has a [Wikidata entry](https://www.wikidata.org/wiki/Q1270860). The entry for \"location of the first performance\" in\n",
    "Wikidata has information about its \"coordinate location\",[^coordinates_property] which provides the corresponding\n",
    "geodata (52°16'1.9\" N, 10°31'28.9\" E). This embedding of DraCor plays in the Linked Open Data\n",
    "Cloud now makes it possible to run SPARQL queries for the entire corpora, for example. \n",
    "\n",
    "[^dracor_wikidata_property]: On Wikidata DraCor IDs are recorded with the DraCor property `P12233`, cf. [https://www.wikidata.org/wiki/Property:P12233](https://www.wikidata.org/wiki/Property:P12233). The DraCor API provides a [\"Mix'n'match\" endpoint](https://dracor.org/doc/api#/wikidata/wikidata-mixnmatch) to allow the Wikidata system to harvest DraCor identifiers, cf. [https://meta.wikimedia.org/wiki/Mix'n'match/Import](https://meta.wikimedia.org/wiki/Mix'n'match/Import). If you want to learn more about DraCor and Wikidata ask for it in the \"Open Topics\"-Session on Wednesday. \n",
    "\n",
    "[^location_of_first_performance_property]: Wikidata Property `P4647`, see [https://www.wikidata.org/wiki/Property:P4647](https://www.wikidata.org/wiki/Property:P4647) for more information.\n",
    "\n",
    "[^coordinates_property]:Wikidata Property `P625`, see [https://www.wikidata.org/wiki/Property:P625](https://www.wikidata.org/wiki/Property:P625) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edef78-9984-49e7-87c7-35ee1209cac1",
   "metadata": {},
   "source": [
    "In the following we will use the SPARQL endpoint of the staging DraCor System at [https://staging.dracor.org/sparql](https://staging.dracor.org/sparql)[^sparql_intro]. We will send a SPARQL query using the Python package `SPARQLWrapper` which provides a convenient way to combine Python and SPARQL. The query we are going to use will retrieve plays contained in the German Drama Corpus (GerDraCor) that are linked to a Wikidata entity. For each such play it will query Wikidata and retrieve the location of the first performance (in most cases a theatre) and its coordinates. We then simplify the returned data structure and turn it into a [GeoPandas](https://geopandas.org) dataframe which will be used to display a map.\n",
    "\n",
    "[^sparql_intro]: For a (slightly outdated) introduction to SPARQL and LOD with DraCor see [this notebook](https://github.com/dracor-org/dracor-notebooks/blob/lod-intro/lod-intro/lod-intro.ipynb). The RDF-Serialization of the DraCor data is currently under development. Meanwhile the SPARQL interface of the production instance of DraCor at (dracor.org)[https://dracor.org] is deactiveated. For testing purposes the staging instance of DraCor can be used. The data is modeled according to an old version of the [DraCor Ontlogy](https://vowl.acdh.oeaw.ac.at/#iri=https://raw.githubusercontent.com/dracor-org/dracor-schema/ontology/ontology/dracor-ontology.xml). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040f948-c9be-4459-be32-60c470f4711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages (These are pre-installed in the Docker container)\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca6b70-2bdf-4820-ad41-cbfe864ca22a",
   "metadata": {},
   "source": [
    "After importing the needed Python packages we assign the federated SPARQL query to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bfe5f2-aa77-4be8-90f8-8dbfffb1e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Queries (i.e. using multiple SPARQL endpoints to combine information) tend to be slow. \n",
    "# The query below may result in a timeout. \n",
    "# If this happens frequently the limit clause (\"LIMIT\") can be set to a smaller number. \n",
    "# Ideally, this would be run with a limit of 700 as there are curently 700 plays in the German Drama Corpus. \n",
    "\n",
    "query = \"\"\"\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX urn: <http://fliqz.com/>\n",
    "PREFIX dracon:<http://dracor.org/ontology#>\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX hint: <http://www.bigdata.com/queryHints#>\n",
    "\n",
    "\n",
    "SELECT * \n",
    "where {\n",
    "  {\n",
    "  select *\n",
    "  WHERE {\n",
    "  graph <urn:x-arq:UnionGraph>  {\n",
    "      ?play dracon:in_corpus <https://dracor.org/ger> ;\n",
    "            owl:sameAs ?wd . \n",
    "        }\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  SERVICE <https://query.wikidata.org/sparql> {\n",
    "  ?wd wdt:P4647 ?location ;\n",
    "      rdfs:label ?playLabel .\n",
    "  \n",
    "  ?location wdt:P625 ?coords ;\n",
    "         rdfs:label ?locationLabel .\n",
    "\n",
    "    FILTER (lang(?locationLabel) = \"en\")\n",
    "    FILTER (lang(?playLabel) = \"de\")\n",
    "  }\n",
    "}\n",
    "LIMIT 200\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643ec0b-3c77-4e06-8a81-b26af61b82ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "You can also test the [SPARQL query](https://staging.dracor.org/sparql#query=PREFIX%20owl%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F2002%2F07%2Fowl%23%3E%0APREFIX%20urn%3A%20%3Chttp%3A%2F%2Ffliqz.com%2F%3E%0APREFIX%20dracon%3A%3Chttp%3A%2F%2Fdracor.org%2Fontology%23%3E%0APREFIX%20wd%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fprop%2Fdirect%2F%3E%0APREFIX%20rdfs%3A%20%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX%20hint%3A%20%3Chttp%3A%2F%2Fwww.bigdata.com%2FqueryHints%23%3E%0A%0A%0ASELECT%20*%20%0Awhere%20%7B%0A%20%20%7B%0A%20%20select%20*%0A%20%20WHERE%20%7B%0A%20%20graph%20%3Curn%3Ax-arq%3AUnionGraph%3E%20%20%7B%0A%20%20%20%20%20%20%3Fplay%20dracon%3Ain_corpus%20%3Chttps%3A%2F%2Fdracor.org%2Fger%3E%20%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20owl%3AsameAs%20%3Fwd%20.%20%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%0A%20%20%7D%0A%20%20%0A%20%20SERVICE%20%3Chttps%3A%2F%2Fquery.wikidata.org%2Fsparql%3E%20%7B%0A%20%20%3Fwd%20wdt%3AP4647%20%3Flocation%20%3B%0A%20%20%20%20%20%20rdfs%3Alabel%20%3FplayLabel%20.%0A%20%20%0A%20%20%3Flocation%20wdt%3AP625%20%3Fcoords%20%3B%0A%20%20%20%20%20%20%20%20%20rdfs%3Alabel%20%3FlocationLabel%20.%0A%0A%20%20%20%20FILTER%20(lang(%3FlocationLabel)%20%3D%20%22en%22)%0A%20%20%20%20FILTER%20(lang(%3FplayLabel)%20%3D%20%22de%22)%0A%20%20%7D%0A%7D%0ALIMIT%20700&endpoint=https%3A%2F%2Fstaging.dracor.org%2Ffuseki%2Fsparql&requestMethod=POST&tabTitle=Location%20of%20first%20performances%20(GerDraCor)&headers=%7B%7D&contentTypeConstruct=application%2Fn-triples%2C*%2F*%3Bq%3D0.9&contentTypeSelect=application%2Fsparql-results%2Bjson%2C*%2F*%3Bq%3D0.9&outputFormat=table) in the [YASGUI](https://yasgui.triply.cc)-based DraCor SPARQL interface on the staging server. The following cell contains the Python code that sends the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea74bfb-bbc5-4ac3-a6d6-b0793771f8c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Send the SPARQL query to the staging.dracor.org server. \n",
    "# It will return the SPARQL results (including the \"bindings\") as JSON which are then converted to a Python-native data structure\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://staging.dracor.org/fuseki/sparql\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "sparql.addExtraURITag(\"timeout\",\"120000\")\n",
    "sparql.setQuery(query)\n",
    "results = sparql.queryAndConvert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106556b-eecb-47df-ab5c-1f07790b79b4",
   "metadata": {},
   "source": [
    "The results are returned in the [SPARQL Query Results JSON Format](https://www.w3.org/TR/sparql12-results-json) and are simplified in the following cell. These data is turned into a GeoPandas Dataframe which can be explored as an interactive map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a941ad-0ba9-4cec-89b0-7a6989ba7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Dataframe/Geopandas Dataframe and explore the map\n",
    "simple_results = []\n",
    "for binding in results[\"results\"][\"bindings\"]:\n",
    "    item = {}\n",
    "    for key in binding.keys():\n",
    "        item[key] = binding[key][\"value\"]\n",
    "    simple_results.append(item)\n",
    "df = pd.DataFrame(simple_results)\n",
    "df['geometry'] = gpd.GeoSeries.from_wkt(df['coords'])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b870e-332f-407b-bd9e-da1e9551baec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-1-3-3)=\n",
    "## 1.3.3 Showcase 3: Extracting Stage Directions for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626ea27-8097-42be-8ade-c3ca7b853c46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "While the previous showcase uses the SPARQL endpoint of our Programmable Corpora prototype DraCor, the following showcase uses the custom developed DraCor API. Alongside the TEI encoded DraCor plays are, among others, various XQuery-based extractor functions, which make it possible, via the DraCor API, to retrieve specific and standardized text segments and use them as input for, for example, Natural Language Processing (NLP) pipelines. Thus, for instance,the TEI-based structure of the data in DraCor can be used to address specific research questions, as in our next showcase.\n",
    "\n",
    "Again, the homogenization of the drama corpora in DraCor serves as a starting point for our showcase. During this homogenization, all plays are systematically structured in such a way that the speaker's text can be consistently differentiated from the stage directions. For this purpose, the corresponding TEI elements are used, where `<stage>`[^tei-stage-element] distinctly tags the text of the stage directions.\n",
    "\n",
    "[^tei-stage-element]: Cf. [Documentation of the element `<stage>`](https://www.tei-c.org/release/doc/tei-p5-doc/en/html/ref-stage.html).\n",
    "\n",
    "The following TEI snippet from Lessing’s “Emilia Galotti” exemplifies the data structure.\n",
    "\n",
    "```\n",
    "<sp who=\"#appiani\">\n",
    "    <speaker>APPIANI</speaker>\n",
    "    <stage>tritt tiefsinnig, mit vor sich hingeschlagnen Augen herein, und\n",
    "    kömmt ihnen näher, ohne sie zu erblicken; bis Emilia ihm entgegen\n",
    "    springt.</stage>\n",
    "    <p>Ah, meine Teuerste! – Ich war mir Sie in dem Vorzimmer nicht vermutend.</p>\n",
    "</sp>\n",
    "```\n",
    "\n",
    "Via the DraCor API it is now possible to get all stage directions of a play with the corresponding\n",
    "request URL: [https://dracor.org/api/v1/corpora/ger/plays/lessing-emilia-galotti/stage-directions](https://dracor.org/api/v1/corpora/ger/plays/lessing-emilia-galotti/stage-directions). \n",
    "\n",
    "On Tuesday In Session 5 we will explain how to use the DraCor API in Python. For demonstration purposes the following cell uses a \"shortcut\" function[^api_get] to request the data from the API and assign it to a variable. We then print an excerpt (some 500 characters) of the returned text data.\n",
    "\n",
    "[^api_get]: There are several ways to retrieve data from the web in Python. A generic way unsing the Python package `requests` will be explained in Session 5 on Tuesday. The function `api_get` is imported from in the `stabledracor`package which we will use in Session 6 on Wednesday. And, of course, there is the Python package [pydracor](https://github.com/dracor-org/pydracor) which provides even more convenient access to the DraCor API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005a65e-30c5-4a52-b04d-2f3606ab840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stabledracor.client import api_get\n",
    "\n",
    "emilia_galotti_stage_directions = api_get(\n",
    "    corpusname=\"ger\", \n",
    "    playname=\"lessing-emilia-galotti\", \n",
    "    method=\"stage-directions\", parse_json=False)\n",
    "\n",
    "print(f\"{emilia_galotti_stage_directions[0:500]} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045a89b-d288-4af7-8a06-bb36bb6dd59b",
   "metadata": {},
   "source": [
    "At the same time, it is possible to retrieve all the spoken texts of the plays via another endpoint. For\n",
    "Lessing’s “Emilia Galotti”, the corresponding request URL would be:\n",
    "https://dracor.org/api/v1/corpora/ger/plays/lessing-emilia-galotti/spoken-text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970508f9-bd4d-4177-b5a2-6b0bec9d52c0",
   "metadata": {},
   "source": [
    "The obtained texts can now be further processed in various ways. In an early showcase, {cite:ts}`trilcke_2020_opening` performed sentence splitting on the text data for all plays in the German-language drama corpus GerDraCor[^gerdracor_used_for_stage_direction_paper] and then compared the average sentence lengths for the stage directions with those of the speaker text. The result showed that the sentence lengths in the speaker texts were longer on average overall, but that at the same time a development can be observed leading to a successive convergence of sentence lengths (see {numref}`sentence-length-datagraph`) – a development that, as the authors have suggested , can be explained in the context of research debates about the epification of drama in the 19th century (cf. {cite:p}`trilcke_2020_opening`).\n",
    "\n",
    "[^gerdracor_used_for_stage_direction_paper]: Regarding the exact data used for the study the authors report on their corpus: \"Of the 474 plays available in GerDraCor, we removed librettos and 3 plays without SD, which yields a corpus of 384 plays that are pre-processed using the DramaNLP package.\" {cite:p}`trilcke_2020_opening` The tool [DramaNLP](https://github.com/quadrama/DramaNLP) was developed in the context of [QuaDramA project](https://quadrama.github.io) as was the R package [DramaAnalysis](https://github.com/quadrama/DramaAnalysis) which was used for the analysis of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33013c-3bd5-40cf-8887-d697fdfca6b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "% Figure is rendered in the HTML output here\n",
    "\n",
    "```{figure} ./images/sentence-length-datagraph.png\n",
    "---\n",
    "width: 600px\n",
    "name: sentence-length-datagraph\n",
    "---\n",
    "Mean Sentence Length in Stage Directions and Spoken Text in GerDraCor plays visualized with Datagraph (cf. {cite:p}`trilcke_2020_opening`)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca14c3-123e-45a7-8fff-4ae31b14b9e0",
   "metadata": {},
   "source": [
    "In the following we will not use the tool that was originally used but at least partly re-implement the algorithm using the Python package [spaCy](https://spacy.io) to demonstrate how the API response containing the text of the stage directions can be split into sentence tokens with the [Sentencizer](https://spacy.io/api/sentencizer) component. If we actually wanted to repeat the study[^repeating_research_outlook] and verify the results this step would have to be done for each play.\n",
    "\n",
    "[^repeating_research_outlook]: On Wednesday in session 6 in his lightnig talk Christof Schöch will go into \"Repeating Research\" in more detail and introduce his conceptual framework and a terminology to describe modes of repeating research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6dc08a-dc75-454a-a3f5-e1031409c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.de import German\n",
    "\n",
    "nlp = German()\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Pass the downloaded stage directions to the NLP pipeline to perform the sentence splitting\n",
    "doc = nlp(emilia_galotti_stage_directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aac862-8ef9-4af5-9dd4-2314626a496b",
   "metadata": {},
   "source": [
    "We can list the first ten sentences to get a feeling if the splitting is acceptable[^hint_on_newline]:\n",
    "\n",
    "[^hint_on_newline]: Some pre-processing of the API response might be necessary to achieve better results, i.e. there are some newline characters `\\n` that should be removed depending on how they are handled in the further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b6c1e-a604-43ff-9175-26d46f21de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(doc.sents)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c571f9-ce1d-4fd9-b59e-f1e90dcde800",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In the above mentioned study the sentence length is measure in tokens. If we wanted to perform a solid repetition of the study we would need to look into how the tokens are created, but this goes beyond this short tutorial. In our re-implementation the pipeline component has already performed a tokenization. If we want to inspect the tokens orf the first sentence we can output them as shown in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e150ee6-01fc-46d3-8c65-6a768c3c4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in list(doc.sents)[0]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16672dfe-eb46-400b-8744-731d3dd1e0ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is needed for the HTML rendering. Please ignore in the Jupyter Lab environement\n",
    "glue(\"first_sentence_token_count\", len(list(doc.sents)[0]), display=None)\n",
    "\n",
    "# Output the number of tokens in the first sentence\n",
    "print(f\"The first sentence consists of {len(list(doc.sents)[0])} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6f478-f192-4f61-9807-de57b28408d8",
   "metadata": {},
   "source": [
    "The first sentence consists of {glue}`first_sentence_token_count` tokens.\n",
    "\n",
    "Now we can iterate over all sentences and create a [pandas](https://pandas.pydata.org) DataFrame which we can use for all sort of calculations, e.g. calculate the mean of the token count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751a930-986f-4f28-a92a-e4c5000afe7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "token_count = []\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    sentences.append(sentence.text)\n",
    "    token_count.append(len(sentence))\n",
    "\n",
    "# Create a dataframe containing the sentence and the token count; \n",
    "# newlines should have been removed from the API response because they are counted as tokens here\n",
    "# (see the remarks about pre-processing the data in footnote 13) \n",
    "df = pd.DataFrame({\"sentence\": sentences, \"token_count\":token_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee641d-46c8-4b0a-841a-6fefd6f26628",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is needed for the HTML rendering. Please ignore in the Jupyter Lab environement\n",
    "glue(\"galotti_mean_of_sentence_length\", df['token_count'].mean().round(2), display=None)\n",
    "\n",
    "# Get the mean of the colum token count\n",
    "print(f\"Mean of sentence lengths in tokens: {df['token_count'].mean().round(2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9640c4d-14f9-4612-aced-e4df9cdb9e74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The mean of the sentence lengths of the play \"Emilia Galotti\" is {glue}`galotti_mean_of_sentence_length`. \n",
    "\n",
    "We can also quickly visualize the lengths of all sentences in the stage directions of the play \"Emilia Galotti\" as a [boxplot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html) ({numref}`sentence_lengths_plot`) which will us allow to better see the distribution of the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d9c74-38e4-481d-8092-3aff14ae13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the package matplotlib for Python to create plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# a quick plot could also be created with a built-in method of the pandas DataFrame\n",
    "# df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d34a24-50ed-4e67-aad4-547ade280b8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.ylabel(\"Sentence length in tokens\", figure=fig)\n",
    "plt.boxplot(df[\"token_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3dafc8-16a9-4431-957f-95e6166c0549",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is needed for the HTML rendering in the Book, ignore in Jupyter Lab\n",
    "glue(\"fig_galotti_boxplot\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f349d4-4eb0-4e70-bc19-6deed36c3e0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{glue:figure} fig_galotti_boxplot\n",
    "---\n",
    "figwidth: 800px\n",
    "name: sentence_lengths_plot\n",
    "---\n",
    "Sentence Length in the stage directions of the play \"Emilia Galotti\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec89f0d5-40fa-46ba-9fa6-405dcc913241",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-1-3-4)=\n",
    "## 1.3.4 Showcase 4: Plotting Network Measures for Thousands of Plays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b28574a-6651-4f3a-95e6-4347af4a1c5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Connected to the DraCor corpora are various microservices that––following the principle of “method as a microservice”––apply specific methods of CLS to the text data in the drama corpora. The outputs from these microservices are, in the form of metrics, made available via the DraCor API. Part of these microservice-based and thus research-driven API functions rely on methods from Social Network Analysis. Again, based on the homogenized TEI structure of the plays in DraCor, in particular the semi-automated speaker identification, a dedicated microservice first automatically constructs network graphs to which then a number of algorithms from Network Analysis are applied.\n",
    "\n",
    "The technical capability to retrieve metrics for the texts from several different drama corpora via one single API enables the use of standardized analyses for comparative literary studies, as {cite:ts}`trilcke_2024_smallworld` have shown applying the concept of “Small World” to almost 3,000 dramas of European literature.[^network_analysis_session]\n",
    "\n",
    "[^network_analysis_session]: This paper will be discussed in more detail in Session 5 on Tuesday.\n",
    "\n",
    "Analyzing plays with reference to the “Small World” concept requires the calculation of the network metric of “Average Path Length”.[^average_path_length_networkx] This metric can, as outlined, be retrieved via the DraCor API. For our final showcase we recreate the DraCor-based environment used in the study and retrieve the “Average Path Length” of each play included in the so-called \"Very Big Drama Corpus\".[^stabledracor_outlook] \n",
    "\n",
    "[^average_path_length_networkx]: For details on the implementation of this measure see the [documentation](https://networkx.org/documentation/networkx-1.3/reference/generated/networkx.average_shortest_path_length.html) of networkx. \n",
    "\n",
    "[^stabledracor_outlook]: In session 6 on Wednesday we will explain how to stabilize a corpus like VeBiDraCor using Docker. \n",
    "\n",
    "The following code cell will take some time to run because it will amongst others download a pre-built and already populated Docker images of the DraCor database and make available the front-end and API at [https://localhost:8088](https://localhost:8088) (see {numref}`vebidracor-frontend`). The research environment used in the Small-World study also included an instance of RStudio which, after successful execution of the cell below, is available at [http://localhost:8787](http://localhost:8787) (see {numref}`smallworld-rstudio`). It can be accessed with the following credentials: username: `rstudio`, password: `smallworld`.[^smallworld_environment]\n",
    "\n",
    "[^smallworld_environment]: For details on the technical setup of the Small-World study see the [Readme](https://github.com/dracor-org/small-world-paper/tree/publication-version) in the repository [https://github.com/dracor-org/small-world-paper](https://github.com/dracor-org/small-world-paper) and CLS INFRA deliverable [D7.3 \"Report On Versioning Living and Programmable Corpora\"](https://zenodo.org/records/11081934) {cite:p}`boerner_2024_versioning-living-corpora`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aeb8f7-e33b-4a91-9aee-36141abda3f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from stabledracor.client import StableDraCor\n",
    "vebidracor = StableDraCor(api_major_version=\"v0\")\n",
    "vebidracor.run(url=\"https://raw.githubusercontent.com/dracor-org/small-world-paper/publication-version/docker-compose.post.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f657f3-566a-4c03-8137-33858bdb6957",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "% Figure is rendered in the HTML output here\n",
    "\n",
    "```{figure} ./images/frontend_loaded_vebidracor.png\n",
    "---\n",
    "width: 600px\n",
    "name: vebidracor-frontend\n",
    "---\n",
    "Front-End of the local DraCor instance with VebiDraCor loaded\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a552420-f654-4a89-a3c8-37f5c5fdc2d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "% Figure is rendered in the HTML output here\n",
    "\n",
    "```{figure} ./images/rstudio_post-analysis-state.png\n",
    "---\n",
    "width: 600px\n",
    "name: smallworld-rstudio\n",
    "---\n",
    "RStudio with the Small-World analysis script loaded\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f11a86-3945-47fc-92e8-ea6e6ad0cec9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can now use the API of the local DraCor instance to retrieve metrics of the corpus from the `/corpora/{corpusname}/metadata` endpoint. It returns a JSON array including aggregate metrics of all plays in a corpus, including a value for “Average Path Length” (`averagePathLength`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035ef6f-a795-4ff0-a3c1-48e79829d0da",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the lazy method to query the API as in the second showcase.\n",
    "# again there are many ways to fetch data from APIs\n",
    "vebidata = api_get(api_base_url=\"http://localhost:8088/api\", \n",
    "                   api_major_version=\"v0\", \n",
    "                   corpusname=\"vebi\", \n",
    "                   method=\"metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cb30b-843f-45b3-92a2-db3b1764c803",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is needed for the HTML rendering\n",
    "glue(\"num_vebidracor_plays\", len(vebidata), display=None)\n",
    "\n",
    "# Output the number of plays in VeBiDraCor\n",
    "print(f\"We downloaded metrics of {len(vebidata)} plays.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104fe380-9e38-46cc-9bf8-9ac7a330e183",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We then convert the data of {glue}`num_vebidracor_plays` plays into a Pandas DataFrame and filter it on the column [`yearNormalized`](https://dracor.org/doc/faq) to get plays between 1500 and 1900. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53231440-8c26-48a6-845c-4d2b84f33ef7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the Pandas DataFrame\n",
    "df = pd.DataFrame(data=vebidata)\n",
    "\n",
    "# Create a new DataFrame based on the first but containing only plays with a normalized date value between 1500 and 1900\n",
    "df_filtered = df[(df[\"yearNormalized\"] >= 1500) & (df[\"yearNormalized\"] <= 1900)]\n",
    "\n",
    "# Output the filtered DataFrame\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f86c9-8f56-4ae7-806f-b3e3b195d6d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is needed for the HTML rendering, ignore in Jupyter Lab\n",
    "\n",
    "# This is needed for the HTML rendering\n",
    "glue(\"count_plays_in_df_filtered\", df_filtered.shape[0], display=None)\n",
    "\n",
    "# Output the number of plays in the filtered DataFrame\n",
    "print(f\"There are {df_filtered.shape[0]} plays in the filtered DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c930b-4da4-4177-b7d0-ca55c039d810",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In a final step, we plot the “Average Path Length” for the now remaining {glue}`count_plays_in_df_filtered` plays as a chart ({numref}`fig_vebidracor_average_path_length`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a2103-7f75-4f6f-92dd-6876418cf4f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.ylabel(\"Average Path Length\", figure=fig)\n",
    "plt.xlabel(\"Year normalized\", figure=fig)\n",
    "plt.ylim(0.9, 3.5)\n",
    "\n",
    "plt.scatter(x=df_filtered[\"yearNormalized\"], \n",
    "            y=df_filtered[\"averagePathLength\"], \n",
    "            facecolors=\"none\", \n",
    "            edgecolors=\"green\",\n",
    "            figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466fddd-2b74-4660-a019-3fb598b32dee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is needed for the HTML rendering in the Book, ignore in Jupyter Lab\n",
    "glue(\"fig_vebidracor_average_path_length\", fig, display=False)\n",
    "\n",
    "# This cell shows the plot in the Notebook in Jupyter Lab\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdaa8b2-2db4-4499-885f-11781f911dca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{glue:figure} fig_vebidracor_average_path_length\n",
    "---\n",
    "figwidth: 800px\n",
    "name: fig_vebidracor_average_path_length\n",
    "---\n",
    "Average Path Length for {glue}`count_plays_in_df_filtered` plays in VeBiDraCor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb36fdc-7f39-4ec7-acdb-2911d7d0707e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "With just a few lines of code we took a decisive step towards a fully-fledged “distant reading” study, whereby at the same time it becomes clear what is still missing in these data (and what would have to be provided in an elaborated study): the interpretation of the data, which has to elaborate the meaning of such plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33368736-a743-4f00-a133-a00f68296ab9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Bibliography\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    ":style: plain\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
