{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# *To catch a protagonist* in DraCor\n",
    "**by Ingo Börner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In the paper [*To catch a Protagonist: Quantitatice Domninance Relations in German-Language Drama (1730-1930)*](https://dh2018.adho.org/to-catch-a-protagonist-quantitative-dominance-relations-in-german-language-drama-1730-1930/) ({cite:t}`fischer_catch_2018`) an algorithm is described, that allows to identify characters that are the quantitatively dominant characters of a play based on a set of network-based and count based measures:\n",
    "\n",
    "> In order to systematically describe the extent of this deviation, we calculate eight values for each character of the 465 dramas of our corpus, three count-based measures (number of scenes a character appears in, number of speech acts, number of spoken words) and five network-related measures (degree, weighted degree, betweenness centrality, closeness centrality, eigenvector centrality). For each measurement a ranking is created. The rankings are then merged into two meta-rankings: one count-based and one network-based. The two meta-rankings are then combined into an overall ranking.\n",
    "\n",
    "The original algorithm was implemented in the tool [Dramavis](https://github.com/lehkost/dramavis) by Christopher Kittel. *Dramavis* operates on XML [\"zwischenformat\"](https://dlina.github.io/Introducing-Our-Zwischenformat) files created in the [DLINA](https://dlina.github.io) project. \n",
    "\n",
    "The following notebook adapts the code of the respective modules to work with data returned by the [DraCor API](https://dracor.org/doc/api). The aim is to be able to recreate the `*_chars.csv`-files that were used in the study. The data can be found in the [repository](https://github.com/dlina/catch-protagonist) on github in the folder [`allmetrics`](https://github.com/dlina/catch-protagonist/tree/main/data/allmetrics).\n",
    "\n",
    "The implementation will be tested with the play *Emilia Galotti*. The original algorithm operated on the corresponding [LINA](https://dlina.github.io/linas/88) and produced the file [`88_Emilia Galotti_chars.csv`](https://github.com/dlina/catch-protagonist/blob/main/data/allmetrics/88_Emilia%20Galotti_chars.csv) as output In DraCor the play can be accessed [here](https://dracor.org/ger/lessing-emilia-galotti).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Get the basic measures\n",
    "\n",
    "We need to get the following basic measures on characters:\n",
    "\n",
    "**Network measures**\n",
    "\n",
    "* betweenness\n",
    "* degree\n",
    "* closeness\n",
    "* ~~closeness corrected~~\n",
    "* weighted degree\n",
    "* eigenvector centrality\n",
    "\n",
    "**count-based measures**\n",
    "\n",
    "* frequency/appearances\n",
    "* number of *speech acts*\n",
    "* number of *words*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network and count-based metrics via Dracor API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python-Packages [`requests`](https://docs.python-requests.org/en/latest/) and the library [`json`](https://docs.python.org/3/library/json.html#module-json) will be used to query the API and parse the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if not installed, uncomment the following line and run the cell:\n",
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set corpus and playname\n",
    "corpusname = \"ger\"\n",
    "playname = \"lessing-emilia-galotti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base url of the DraCor-API\n",
    "api_base = \"https://dracor.org/api/v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To retrieve the network-data and speech-amounts data on single characters the function `/corpora/{corpusname}/plays/{playname}/characters` is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# send a request to the endpoint and parse results\n",
    "request_url = api_base + \"corpora/\" + corpusname + \"/plays/\" + playname + \"/characters\"\n",
    "print(request_url)\n",
    "r = requests.get(request_url)\n",
    "character_data = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API function returns data on the characters, including the network and count-based metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data on the characters are in a dictionary:\n",
    "```\n",
    "{'betweenness': 0.24696969696969698,\n",
    "  'closeness': 0.8,\n",
    "  'degree': 9,\n",
    "  'eigenvector': 0.44898463593218985,\n",
    "  'gender': 'MALE',\n",
    "  'id': 'marinelli',\n",
    "  'isGroup': False,\n",
    "  'name': 'Marinelli',\n",
    "  'numOfScenes': 19,\n",
    "  'numOfSpeechActs': 221,\n",
    "  'numOfWords': 4343,\n",
    "  'weightedDegree': 30}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know anything about the network metrics of the whole play, though. If we want to retrieve this information, we would have to use the API function `/corpora/{corpusname}/play/{playname}/metrics`, which would also tell us, if there are several sub-networks in a dictionary-field with the key `numConnectedComponents`. This could be relevant, because we can also calculate some network-metrics differently, e.g. the *closeness*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Get the metrics and construct a pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Dramavis implementation an object of the class `DramaAnalyzer` is created, which contains the information on characters in a pandas data frame. We will create the same data structure to be able to use the same methods for calculating means and ranking.\n",
    "\n",
    "The rows in the [table](https://raw.githubusercontent.com/dlina/catch-protagonist/main/data/allmetrics/88_Emilia%20Galotti_chars.csv) are:\n",
    "\n",
    "`name,betweenness,degree,closeness,closeness_corrected,strength,eigenvector_centrality,avg_distance,avg_distance_corrected,frequency,speech_acts,words,lines,chars ...`\n",
    "\n",
    "We will not include all rows, but only the ones, that are relevant for the rankings:\n",
    "\n",
    "`name`,`betweenness`,`degree`,`closeness`,~~closeness_corrected~~,`strength`,`eigenvector_centrality`,~~avg_distance,avg_distance_corrected~~,`frequency`,`speech_acts`,`words`,~~lines,chars~~ ...\n",
    "\n",
    "following rows will be called differently to follow DraCor conventions of the [API output](https://dracor.org/api/corpora/ger/play/lessing-emilia-galotti/cast):\n",
    "\n",
    "* `name` → `id`; later this will be used to construct URIs\n",
    "* `strength` → `weightedDegree`\n",
    "* `eigenvector_centrality` → `eigenvector`\n",
    "* `frequency` → `numOfScenes`\n",
    "* `speech_acts` → `numOfSpeechActs`\n",
    "* `words` → `numOfWords`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package [`pandas`](https://pandas.pydata.org/) is used to handle the data as a dataframe. Therefore we need to import the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not installed, uncomment the following line and run the cell:\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to transform the parsed JSON API response to a list of lists, that is then turned into the data frame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# columns\n",
    "cols = [\"id\",\"betweenness\",\"degree\",\"closeness\",\"weightedDegree\",\"eigenvector\",\"numOfScenes\",\"numOfSpeechActs\",\"numOfWords\"]\n",
    "\n",
    "# prepare the data for the data frame\n",
    "df_data = []\n",
    "for character in character_data:\n",
    "    row = []\n",
    "    for key in cols:\n",
    "        row.append(character[key])\n",
    "    df_data.append(row)\n",
    "\n",
    "# construct the data frame\n",
    "df = pd.DataFrame(df_data, columns = cols)\n",
    "\n",
    "#turn the column \"id\" to the index\n",
    "df = df.set_index('id')\n",
    "#output\n",
    "df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now query the data, e.g. output the values of a single character by requesting a row by its index value, which is the `id` of the character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values of a single character\n",
    "df.loc[\"marinelli\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Calculate the ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Dramavis the function [`get_character_ranks`](https://github.com/lehkost/dramavis/blob/v0.4/dramalyzer.py#L282-L288) creates the rankings of the count-based and network-based measures. We will adapt this function to operate on the created data frame and rename the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_rank = ['degree', 'closeness', 'betweenness', 'weightedDegree', 'eigenvector', 'numOfScenes', 'numOfSpeechActs', 'numOfWords']\n",
    "for metric in metrics_to_rank:\n",
    "    df[metric + \"_rank\"] = df[metric].rank(method='min', ascending=False)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Rank on average and standard deviation of the individual rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Dramavis the individual rankings are then used for the calculation of an average ranking and the standard deviation, which are then also ranked. This is done by the function [`get_centrality_ranks`](https://github.com/lehkost/dramavis/blob/v0.4/dramalyzer.py#L305-L310).\n",
    "\n",
    "The following columns will be added to the data frame:\n",
    "\n",
    "* (1) `centrality_rank_avg`: The average of all rankings\n",
    "* (2) `centrality_rank_std`: Standard deviation of the rankings\n",
    "* (3) `centrality_rank_avg_rank`: A ranking is created from the average of all rankings (1)\n",
    "* (4) `centrality_rank_std_rank`: A ranking is created from the standard deviation of all rankings (2)\n",
    "\n",
    "The following dramavis code is adapted accordingly to operate on the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [c for c in df.columns if c.endswith(\"rank\")]\n",
    "df['centrality_rank_avg'] = df[ranks].sum(axis=1)/len(ranks)\n",
    "df['centrality_rank_std'] = df[ranks].std(axis=1)/len(ranks)\n",
    "for metric in ['centrality_rank_avg', 'centrality_rank_std']:\n",
    "    df[metric + \"_rank\"] = df[metric].rank(method='min', ascending=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the calculation of `centrality_rank_avg_rank`, the \"central\" characters can be already queried as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"centrality_rank_avg_rank\"] == 1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Step: Create Rankings and combined rankings of network-based and count-based metrics separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to a ranking that combines all metrics and rankings derived thereof, the function [`get_structural_ranking_measures`](https://github.com/lehkost/dramavis/blob/v0.4/dramalyzer.py#L318-L330) treats network-based and count-based values separately and only then aggregates them to a combined overall ranking.\n",
    "\n",
    "The function adds the following rows to the data frame:\n",
    "\n",
    "* (1) `avg_graph_rank`: a ranking based on the rankings of the network-values (*degree*, *closeness*, *betweenness*, *strength* or *weightedDegree* and *eigenvector centrality* or *eigenvector*)\n",
    "* (2) `avg_content_rank`: a ranking based on the rankings of the count-based values (*frequency* or *numOfScenes*, *speech acts* and *words*)\n",
    "* (3) `overall_avg`: the two rankings (1+2) are combined by calculating the mean\n",
    "* (4) `overall_avg_rank`: based on the overall average (3) a ranking is created\n",
    "\n",
    "The following code is adapted accordingly to operate on the dataframe. The ranking stability measures are not implemented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renamed the columns to match the DraCor values here:\n",
    "graph_ranks = ['degree_rank', 'closeness_rank', 'betweenness_rank', 'weightedDegree_rank', 'eigenvector_rank']\n",
    "content_ranks = ['numOfScenes_rank', 'numOfSpeechActs_rank', 'numOfWords_rank']\n",
    "avg_graph_rank = df[graph_ranks].mean(axis=1).rank(method='min')\n",
    "avg_content_rank = df[content_ranks].mean(axis=1).rank(method='min')\n",
    "df[\"avg_graph_rank\"] = avg_graph_rank\n",
    "df[\"avg_content_rank\"] = avg_content_rank\n",
    "df[\"overall_avg\"] = df[[\"avg_graph_rank\", \"avg_content_rank\"]].mean(axis=1)\n",
    "df[\"overall_avg_rank\"] = df[\"overall_avg\"].rank(method='min')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the calculation of `overall_avg_rank`, the \"central\" characters can be queried as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df[\"overall_avg_rank\"] == 1].index.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
